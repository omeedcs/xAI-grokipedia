{
  "topic": "Consciousness",
  "title": "Consciousness",
  "slug": "consciousness",
  "grokipedia_slug": "Consciousness",
  "grokipedia_url": "https://grokipedia.com/page/Consciousness",
  "source": "grokipedia",
  "content": "# Consciousness\n\nConsciousness is the subjective state of awareness and responsiveness to one's internal mental states—such as thoughts, emotions, perceptions, and sensations—and external environment, enabling the integration and processing of information through sensory inputs, reasoning, imagination, and memory. This multifaceted phenomenon encompasses both phenomenal experience (the \"what it is like\" quality of subjective feelings) and access consciousness (the availability of information for cognitive processes like reportability and decision-making). In humans, it relies on complex neural activity, particularly involving the thalamus, prefrontal cortex, and ascending reticular activating system, which support wakefulness and information integration.\n\nPhilosophically, consciousness has been debated since antiquity, with key questions centering on its nature, origins, and relation to the physical world, often framed by the \"hard problem\" of explaining why and how physical processes in the brain give rise to subjective experience. In neuroscience, research focuses on identifying neural correlates of consciousness (NCCs)—the minimal set of neural events jointly sufficient for any specific conscious state—distinguishing global states (e.g., levels of arousal) from content-specific states (e.g., perceiving a color). Prominent theories include higher-order theories, which posit consciousness arises from meta-representations of mental states; global neuronal workspace theory, emphasizing broadcast of information across brain networks for cognitive access; re-entry and predictive processing theories, highlighting recurrent neural interactions and error-minimizing predictions; and integrated information theory, which quantifies consciousness as the degree of irreducible causal integration (measured by Φ) in a system.\n\nEmpirical studies, including neuroimaging and lesion analyses, reveal that consciousness is disrupted in conditions like coma or anesthesia, underscoring its dependence on synchronized brain activity. Yet challenges persist in bridging the explanatory gap between objective neural mechanisms and first-person phenomenology. Evolutionary perspectives suggest consciousness emerged as an adaptive trait for intentional control and social coordination, potentially present in varying degrees across animals with complex nervous systems. Ongoing interdisciplinary efforts, including a 2025 adversarial collaboration testing global neuronal workspace and integrated information theories, aim to resolve debates over whether consciousness is purely computational, electromagnetic, or fundamentally non-reducible—as well as whether it can emerge in artificial intelligence—informing fields from AI development to clinical treatments for disorders of consciousness.\n\n## Defining Consciousness\n\n### Etymology\n\nThe term \"consciousness\" derives from the Latin *conscientia*, literally meaning \"knowledge-with\" or \"shared knowledge,\" formed from *con-* (\"with\") and *scire* (\"to know\"). In ancient Roman usage, particularly in the works of Cicero, *conscientia* primarily connoted moral awareness, such as an inner sense of guilt or praiseworthiness associated with one's actions, rather than a general state of mental awareness.\n\nBy the 17th century, the term evolved in philosophical discourse to encompass broader mental states, particularly self-awareness and immediate cognition. René Descartes played a pivotal role in this shift, employing \"consciousness\" in his *Meditations on First Philosophy* (1641) to describe the introspective certainty of thought in his famous dictum \"cogito ergo sum\" (\"I think, therefore I am\"), where consciousness denotes direct acquaintance with one's own mental contents. This marked a transition from moral connotations to a focus on subjective mental presence, influencing subsequent English usage from the 1630s onward to signify internal knowledge and awareness of one's mind.\n\nCross-culturally, analogous concepts appear in ancient Greek and Indian traditions. In Greek philosophy, Plotinus used *synaisthesis* (\"joint perception\" or \"sensed-with\") in his *Enneads* to describe a unified sensory awareness distinguishing higher cognitive faculties from mere sensation, a term later adopted by 17th-century thinkers like Ralph Cudworth to translate early notions of consciousness. In Sanskrit, *chetana* (or *cetanā*) refers to vital awareness or consciousness, often linked to the animating principle of life in philosophical texts like those of Ayurveda and Vedanta, emphasizing sentience as opposed to inert matter.\n\nIn the 19th and 20th centuries, psychologists expanded the term to capture dynamic subjective experience. William James, in *The Principles of Psychology* (1890), introduced the metaphor of the \"stream of consciousness\" to depict thought as a continuous, flowing process rather than discrete elements, influencing both psychology and literary theory by highlighting its personal, ever-changing nature.\n\n### Conceptual Challenges\n\nOne of the core challenges in conceptualizing consciousness stems from the lack of consensus on whether it constitutes a singular, unified phenomenon or a heterogeneous cluster of cognitive and experiential processes. This ambiguity fuels debates between proponents of introspection-based accounts, which rely on first-person reports of inner experience to define consciousness, and those advocating behaviorist or functionalist approaches that prioritize third-person observable actions and adaptations as the primary indicators.\n\nA longstanding metaphor illustrating these tensions is the \"Cartesian theater\" model, which depicts consciousness as an inner audience passively viewing mental contents on a central stage, implying a unified locus of awareness. This model, rooted in Cartesian dualism, has faced sharp critiques for oversimplifying the brain's distributed processing, as it fails to account for the parallel, non-centralized nature of perceptual and cognitive integration without a privileged \"spotlight\" of attention.\n\nSuch definitional vagueness profoundly influences research, fostering silos across disciplines; for instance, philosophers often emphasize the irreducibility of subjective qualia, while neuroscientists focus on measurable neural correlates, hindering integrated progress toward a cohesive framework.\n\nProminent critiques underscore the experiential inaccessibility at the heart of these challenges. In his 1974 essay \"What Is It Like to Be a Bat?\", Thomas Nagel contends that even complete objective knowledge of a bat's neurophysiology cannot capture the subjective \"what it is like\" to echolocate, revealing the inherent limits of third-person science in addressing first-person phenomenology. Similarly, David Chalmers, in his 1995 paper \"Facing Up to the Problem of Consciousness,\" delineates the \"easy problems\" as explaining cognitive functions like attention and reportability through mechanistic terms, while the \"hard problem\" persists in accounting for why these functions give rise to any subjective experience at all, resisting physicalist reduction.\n\n### Interdisciplinary Definitions\n\nIn philosophy, consciousness is fundamentally defined as the capacity for subjective experience, or \"what it is like\" to have a particular perspective on the world, as articulated by Thomas Nagel in his seminal 1974 essay examining the irreducibility of bat consciousness to human understanding. This view emphasizes the first-person nature of phenomenal experience, distinguishing it from objective descriptions of mental processes. David Chalmers built on this in 1995 by framing consciousness as the \"hard problem\" of explaining why physical brain states give rise to subjective feelings, rather than merely functional behaviors.\n\nFrom a scientific perspective, particularly in cognitive neuroscience, consciousness is operationalized as the global broadcasting or integration of information across neural networks, enabling widespread access to selected mental contents. Bernard Baars' Global Workspace Theory, introduced in 1988, likens this to a theater metaphor where unconscious processes compete for entry into a central \"workspace\" of attention, making information available for report, decision-making, and action. This framework shifts focus from qualia to functional mechanisms, positing consciousness as an emergent property of coordinated brain activity rather than isolated modules.\n\nIn medicine, consciousness is clinically defined as the combined presence of wakefulness (sustained arousal, often measured by eye-opening) and awareness (responsive interaction with the environment), as per the American Academy of Neurology's 2018 updated practice guidelines on disorders of consciousness, developed in collaboration with the American Congress of Rehabilitation Medicine and National Institute on Disability, Independent Living, and Rehabilitation Research. These standards guide diagnosis in conditions like coma or minimally conscious states, prioritizing behavioral and neurophysiological indicators to differentiate levels of preserved function.\n\nLegally, consciousness intersects with criminal responsibility through the doctrine of *mens rea*, which requires a culpable mental state—such as intentionality or knowledge of wrongdoing—for liability, implying awareness of one's actions at the time of the offense, as outlined in U.S. federal criminal law analyses. In end-of-life contexts, consciousness informs rulings on persistent vegetative states, where judicial decisions addressing brain death criteria mismatches have upheld withdrawal of life-sustaining treatment based on the irreversible absence of awareness, balancing patient autonomy with medical evidence.\n\nRecent interdisciplinary efforts, such as the Templeton World Charity Foundation's Accelerating Research on Consciousness (ARC) initiative launched in 2023 and ongoing as of 2025, foster consensus by funding multifactorial empirical tests of theories, integrating philosophical, neuroscientific, and clinical criteria to advance unified working definitions.\n\n## Philosophical Foundations\n\n### Mind-Body Dualism and Monism\n\nMind-body dualism posits a fundamental distinction between the mind, characterized as a non-physical entity, and the body, understood as a physical substance. René Descartes, in his seminal work *Meditations on First Philosophy*, articulated substance dualism by arguing that the mind is a thinking thing (*res cogitans*), defined by its capacity for consciousness and thought, while the body is an extended, non-thinking substance (*res extensa*). This view maintains that consciousness arises from the mind's independent substance, separate from the brain's physical processes. A variant, property dualism, accepts that minds and bodies are the same substance but contends that mental properties, such as qualia, are irreducible to physical properties, as defended by David Chalmers in *The Conscious Mind*, where he argues that phenomenal experience does not logically supervene on physical facts.\n\nMonism, in contrast, rejects such divisions by asserting that reality is a single substance, with consciousness either fully physical or fully mental. Materialist monism, a dominant form, views consciousness as an emergent property of brain processes; U.T. Place's 1956 paper \"Is Consciousness a Brain Process?\" proposed that conscious states are identical to neurophysiological events, challenging phenomenological objections by analogy to theoretical terms in science. J.J.C. Smart extended this in 1959 with \"Sensations and Brain Processes,\" advocating type-identity theory, where specific mental states correspond directly to specific brain states, dismissing introspective reports as irrelevant to ontological claims. Idealist monism, exemplified by George Berkeley's *A Treatise Concerning the Principles of Human Knowledge*, holds that reality consists solely of minds and their ideas, with physical objects being perceptions in perceiving minds, thus rendering consciousness foundational to existence.\n\nDualism faces significant critiques, particularly regarding interactionism, the view that mind and body causally influence each other. Princess Elisabeth of Bohemia, in her 1643 correspondence with Descartes, questioned how an immaterial mind could interact with a material body without violating spatial and mechanical principles, highlighting the problem of causal transmission across substances. This issue persists in modern physics, as non-physical causation would seemingly breach conservation laws of energy and momentum. Epiphenomenalism emerges as a partial response within dualism or materialism, positing consciousness as a causally inert byproduct of brain activity; Thomas Huxley introduced this in his 1874 lecture \"On the Hypothesis that Animals are Automata,\" likening mental states to steam from an engine—produced by physical processes but exerting no influence.\n\nContemporary developments refine these debates, with Chalmers maintaining his property dualist stance through naturalistic dualism, arguing that while consciousness may supervene naturally on physical processes, reductive materialism fails to explain why specific physical states give rise to experience, necessitating non-reductive approaches. Recent philosophical surveys, such as the 2020 PhilPapers Survey (published 2023), indicate shifting views on monism, with physicalism accepted or leaned toward by 35.94% of philosophers (down from 51.9% in 2009), and alternatives like panpsychism rising to 7.55%. As of 2025, debates on consciousness in artificial intelligence, including symposiums questioning whether AI can achieve phenomenal experience, further challenge materialist assumptions without resolving the hard problem. These positions underscore ongoing tensions between viewing consciousness as ontologically distinct or fully integrated with the physical world.\n\n### Qualia and Subjective Experience\n\nQualia refer to the subjective, qualitative aspects of conscious experiences, often described as the \"what it is like\" to have particular sensations, such as the redness of red or the sharpness of pain. These phenomenal properties are posited to be intrinsic and ineffable, inaccessible to third-person description. The privacy of qualia is illustrated by the inverted spectrum thought experiment, originally proposed by John Locke in his *Essay Concerning Human Understanding* (1689), where he imagined two individuals whose color experiences are systematically inverted—such that one's red is the other's green—yet they use color terms indistinguishably in everyday language. This scenario, modernized by Ned Block in his 1990 paper \"Inverted Earth,\" extends the inversion to an external environment where colors are complemented, highlighting how functional equivalence cannot capture the subjective essence of experience, thereby underscoring qualia's inherent subjectivity and resistance to objective analysis.\n\nA central challenge posed by qualia is the \"hard problem\" of consciousness, articulated by David Chalmers in his 1995 paper \"Facing Up to the Problem of Consciousness.\" Chalmers distinguishes between \"easy problems,\" which concern the functional mechanisms of cognition like reportability and behavior, and the hard problem: explaining why physical processes in the brain give rise to any subjective experience at all, rather than merely performing their functions without the \"raw feel\" of qualia. This problem arises because even a complete physical description of neural activity seems insufficient to account for the phenomenal character of experience, suggesting a potential explanatory gap between objective science and subjective reality.\n\nPhilosophical arguments for the reality of qualia include Frank Jackson's knowledge argument, presented in his 1982 paper \"Epiphenomenal Qualia,\" via the thought experiment of Mary, a neuroscientist who knows all physical facts about color vision but has never seen color herself while confined to a black-and-white room. Upon release, Mary learns something new—what it is like to see red—implying that qualia constitute non-physical facts beyond physical knowledge. In response, functionalists like Daniel Dennett argue in his 1988 essay \"Quining Qualia\" (elaborated in *Consciousness Explained*, 1991) that qualia are illusory or incoherent constructs, arising from introspective confusions rather than genuine intrinsic properties; experiences are fully explained by their functional roles, and appeals to ineffable qualia fail under scrutiny because no coherent notion survives philosophical analysis. These debates play a key role in mind-body dualism by suggesting that qualia may necessitate non-physical aspects of mind if physicalism cannot accommodate them.\n\nRecent philosophical surveys reflect ongoing contention over qualia realism. The 2020 PhilPapers Survey, results published in 2023, queried professional philosophers on theories of perceptual experience, finding that only 15.12% accept or lean toward a traditional qualia theory, with 39.30% favoring representationalism (which often incorporates phenomenal aspects) and 15.65% disjunctivism, indicating broad acknowledgment of subjective experience but divergence on qualia's metaphysical status. Despite eliminativist challenges, qualia remain a cornerstone in discussions of phenomenal consciousness, influencing arguments for non-reductive views of the mind.\n\n### Types and Levels of Consciousness\n\nConsciousness is often categorized into distinct types based on its functional and experiential dimensions. A fundamental distinction lies between phenomenal consciousness and access consciousness. Phenomenal consciousness refers to the subjective, qualitative aspects of experience, often described as the \"what it is like\" to have a particular mental state, rooted in the philosophical concept of qualia. Access consciousness, in contrast, pertains to the availability of mental contents for cognitive processes such as reasoning, verbal report, and the control of behavior, enabling information to be globally accessible within the cognitive system. This dichotomy, proposed by Ned Block, highlights that a mental state can possess phenomenal qualities without being accessible for report or action, and vice versa, challenging assumptions that equate subjective feeling with cognitive utility.\n\nAnother key classification differentiates between creature consciousness and state consciousness. Creature consciousness attributes awareness to an entire organism, indicating that the being as a whole is awake and responsive to its environment through its mental states. State consciousness, however, applies to specific mental states themselves, where a state is conscious if it is the target of a higher-order thought or representation by the creature, as articulated in David Rosenthal's higher-order thought theory. This framework posits that for a mental state to be conscious, the organism must have a meta-representational awareness of it, distinguishing conscious states from unconscious ones within an otherwise conscious creature.\n\nConsciousness can also be understood in terms of levels, ranging from minimal to more complex forms. Minimal consciousness represents the most basic degree of awareness, involving rudimentary phenomenal experience without higher integration or self-reference, sufficient for simple sensory responsiveness. Primary consciousness builds upon this as sensory or perceptual awareness, encompassing direct engagement with environmental stimuli through categorization and basic memory, but lacking explicit self-reflection. Secondary consciousness extends to higher-order reflective processes, such as metacognition, where individuals monitor and evaluate their own mental states, enabling abstract thought and self-awareness. These levels form a progression from raw experiential immediacy to sophisticated introspective capacity, though debates persist on whether they constitute discrete stages or a continuum.\n\nRecent neurophilosophical discussions have explored consciousness through nested hierarchies, contrasting global and local forms. Global consciousness involves widespread integration across neural or cognitive networks, where awareness emerges from holistic information broadcasting or high levels of systemic interconnectedness. Local consciousness, conversely, arises from localized processes, such as recurrent activity in specific brain regions, without requiring broad dissemination. This hierarchical view posits consciousness as multilayered, with local elements aggregating into global phenomena.\n\n## Scientific Investigations\n\n### Neural Correlates and Brain Mechanisms\n\nThe neural correlates of consciousness (NCC) refer to the minimal set of neuronal events and mechanisms sufficient for a specific conscious percept, identified through empirical studies linking brain activity to subjective reports. Research has pinpointed several key brain structures involved in generating and sustaining conscious experience, including thalamo-cortical loops that facilitate bidirectional communication between the thalamus and cortex, essential for modulating arousal and sensory processing underlying awareness. These loops, particularly involving intralaminar and higher-order thalamic nuclei, synchronize cortical activity to support the transition from unconscious to conscious states, as demonstrated in electrophysiological recordings where thalamic stimulation restores consciousness in anesthetized animals.\n\nThe prefrontal cortex plays a critical role in integrating diverse sensory inputs into a unified conscious representation, acting as a hub for executive control and working memory that amplifies selected information for global access. Functional imaging studies show heightened prefrontal activation during tasks requiring conscious report, contrasting with subliminal processing confined to posterior regions. Additionally, the claustrum, a thin sheet-like structure beneath the insula, has been proposed as a potential \"switch\" for coordinating consciousness by integrating multisensory signals across cortical areas, based on its dense reciprocal connections with sensory and motor regions. Recent functional MRI studies at 7T resolution confirm claustral activation during visual tasks, supporting its involvement in conscious perception, with consistent responses across hemispheres and sessions.\n\nEmpirical correlates distinguish phenomenal consciousness—the raw feel of experience—from access consciousness—the availability for report and action. The posterior cortical \"hot zone,\" encompassing visual areas V1 through V4 in the occipital and parietal lobes, is primarily associated with phenomenal aspects, such as the qualia of visual scenes, where lesions or stimulation directly alter subjective vividness without affecting behavioral access. In contrast, anterior regions, including frontoparietal networks, correlate with access consciousness, enabling the ignition and broadcasting of content for cognitive use, as evidenced by sustained high-amplitude signals in these areas during conscious detection tasks. This posterior-anterior distinction arises from masking and binocular rivalry paradigms, where unconscious processing remains posterior while conscious breakthroughs recruit anterior ignition.\n\nElectrophysiological techniques have revealed oscillatory patterns linked to conscious binding, the process unifying features into coherent percepts. Electroencephalography (EEG) recordings show gamma-band oscillations around 40 Hz synchronizing across distant brain regions during conscious perception, hypothesized to resolve the binding problem by temporally coordinating neural assemblies. These gamma waves, prominent in thalamocortical circuits, increase in power and coherence when stimuli reach awareness, as seen in attentional blink tasks where bound objects elicit stronger 40 Hz activity than unbound ones. Complementing this, Libet's seminal experiments using EEG demonstrated that readiness potentials in motor areas precede conscious intention by approximately 350 milliseconds, suggesting unconscious initiation of voluntary acts while conscious will arises later for veto purposes.\n\nRecent optogenetic studies in rodents have identified minimal neural ensembles sufficient for driving percepts akin to basic awareness. In mice, targeted activation of just 20-50 neurons in layer 2/3 of the visual cortex via channelrhodopsin elicits reliable behavioral reports of perceived stimuli, recruiting broader network activity while establishing a lower bound on the scale needed for cortical-driven perception. These findings, using precise light pulses to mimic natural firing, indicate that sparse, synchronized activity in sensory areas can suffice for conscious-like detection, paving the way for dissecting NCC at cellular resolution.\n\nA landmark empirical study published in 2025 by the Cogitate Consortium used functional MRI and magnetoencephalography on 250 participants to adversarially test predictions of global neuronal workspace theory (GNWT) and integrated information theory (IIT). The results challenged key aspects of both theories, showing that conscious perception involves widespread posterior-to-anterior signaling without clear ignition in frontoparietal networks as predicted by GNWT, and limited support for IIT's posterior \"hot zone\" complexity measures, highlighting the need for refined models of neural correlates.\n\n### Measurement Techniques\n\nVerbal reports and behavioral tests serve as foundational methods for assessing consciousness by relying on subjects' ability to indicate awareness of stimuli or self. In human experiments, participants often provide introspective accounts of their perceptual experiences, such as detecting masked visual targets, to distinguish conscious from unconscious processing. These subjective measures, while prone to bias, are complemented by objective behavioral tasks; for instance, signal detection paradigms quantify awareness through discrimination accuracy and bias adjustments. In evaluating machine or artificial awareness, Turing-like tasks probe whether systems can convincingly simulate human-like responses to perceptual challenges, serving as proxies for conscious access though not definitive for qualia. For non-human animals, the mirror self-recognition test, introduced by Gallup in 1970, evaluates self-awareness by observing if subjects use a mirror to inspect marked body parts, with chimpanzees demonstrating this capacity after exposure to their reflections.\n\nNeuroimaging techniques provide objective metrics by capturing brain activity patterns associated with conscious states. Functional magnetic resonance imaging (fMRI) measures blood-oxygen-level-dependent (BOLD) signals to compare neural responses in conscious versus unconscious conditions, such as in binocular rivalry or masking experiments, where conscious perception correlates with amplified and sustained activity across sensory and higher-order areas. Electroencephalography (EEG), often combined with transcranial magnetic stimulation (TMS), enables the perturbational complexity index (PCI), a metric developed by Casali et al. in 2013 that quantifies the spatiotemporal complexity of cortical responses to perturbations; PCI values range from low in deep sleep or anesthesia (indicating reduced consciousness) to high in wakefulness, independent of sensory input or motor output. These methods have facilitated the detection of neural correlates of consciousness, revealing distinct signatures like integrated information flow during aware states.\n\nDespite their utility, measuring consciousness faces significant challenges, including confounds from attention, which can enhance processing without necessarily implying awareness. Experimental designs must isolate these factors, as attentional modulation can mimic conscious effects in both behavioral and neural data, complicating causal inferences. Advancements in 2024 leveraged AI to decode neural signals in locked-in patients, enabling real-time interpretation of attempted speech or intentions from EEG or invasive recordings, thus bypassing verbal limitations and revealing covert awareness.\n\nComposite scales integrate multiple indicators to assess consciousness levels in clinical contexts. The Coma Recovery Scale-Revised (CRS-R), developed in 2004, evaluates disorders of consciousness through subscales measuring auditory, visual, motor, oromotor, communication, and arousal functions, with total scores reflecting transitions from coma to emergence; it distinguishes arousal (wakefulness) from awareness (responsive interaction) for prognostic purposes.\n\n### Evolutionary and Functional Roles\n\nConsciousness is proposed to serve several adaptive functions in biological systems, primarily enhancing decision-making by integrating diverse sensory inputs for survival-oriented actions. According to global workspace theory, conscious processing allows for the broadcasting of information across neural networks, facilitating complex problem-solving and voluntary control in uncertain environments. This function is evident in how conscious awareness enables the prioritization of relevant stimuli, such as detecting predators or foraging opportunities, thereby improving behavioral flexibility. Additionally, consciousness supports social coordination, including the development of theory of mind, which allows individuals to infer others' mental states and foster cooperative behaviors essential for group living. These roles suggest that consciousness evolved to optimize interactions in social and ecological contexts, promoting reproductive success.\n\nThe evolutionary timeline of consciousness traces its emergence to approximately 500-520 million years ago, coinciding with the development of vertebrate brains during the Cambrian Period. Fossil and genetic evidence indicates that early vertebrates, such as jawless fish, possessed neural structures capable of basic phenomenal experience, marking the onset of subjective awareness. Debates persist between gradualist views, positing a slow accumulation of neural complexity over pre-Cambrian lineages, and threshold models linking a sudden emergence to the Cambrian explosion, where diverse body plans and sensory systems rapidly evolved. This explosion, around 540 million years ago, is hypothesized to have driven the adaptive radiation of conscious processing as animals faced novel competitive pressures.\n\nComparative studies provide evidence that consciousness correlates with increasing brain complexity, as measured by the encephalization quotient (EQ), which adjusts brain size relative to body mass. Higher EQ values in mammals and birds align with advanced cognitive capacities, including self-awareness and flexible learning, suggesting an evolutionary progression toward richer conscious states. Analyses of fossil endocasts from early mammals, dating to around 190 million years ago, reveal unexpectedly large brains relative to body size, indicating potential for heightened sensory integration and awareness even in primitive forms. These findings support the view that consciousness scaled with neural elaboration to meet environmental demands.\n\nCritiques of these functional accounts include illusionism, which posits that qualia—the subjective feels of experience—serve no distinct adaptive purpose and are illusory byproducts of cognitive processes. Philosopher Daniel Dennett argues that evolutionary pressures favor functional behaviors without requiring intrinsic phenomenal qualities, as neural mechanisms alone suffice for survival advantages. This perspective challenges the necessity of consciousness beyond unconscious computation, suggesting that apparent qualia arise from introspective judgments rather than evolved traits.\n\n## Theoretical Models\n\n### Global Workspace and Integrated Information\n\nGlobal Workspace Theory (GWT), proposed by Bernard Baars in 1988, posits that consciousness arises from the broadcasting of selected information to a central \"global workspace\" within the cognitive system, making it available for widespread access by various brain processes. This workspace acts as a hub where sensory inputs, memories, and goals compete for entry, and only those surpassing an \"ignition threshold\" become conscious, enabling coordinated action and reportability. In the 2000s, Stanislas Dehaene and colleagues extended this into the Global Neuronal Workspace (GNW) model, linking it to neural mechanisms such as prefrontal and parietal cortices, where conscious ignition involves a burst of long-range connectivity and sustained activity.\n\nIntegrated Information Theory (IIT), introduced by Giulio Tononi in 2004, defines consciousness as the capacity of a system to integrate information in an irreducible way, quantified by the measure Φ (phi), which captures the system's causal power beyond its parts. IIT starts from phenomenological axioms—such as the existence, composition, information, integration, and exclusion of conscious experience—and derives postulates for physical systems that maximize Φ, implying that consciousness is intrinsic to any substrate with sufficient causal integration. In its 2023 update (IIT 4.0), the theory refines these axioms and postulates to better align with empirical data on phenomenal structure, emphasizing that consciousness corresponds to the properties of physical mechanisms generating experience.\n\nGWT and IIT differ fundamentally in their approaches: GWT is a functional and computational model focused on the dissemination of information for behavioral utility, whereas IIT provides an intrinsic and quantitative account rooted in causal structure, aiming to identify the necessary and sufficient conditions for any experience. Empirical tests, such as those contrasting posterior cortical integration (predicted by IIT) with frontoparietal ignition (predicted by GNW), have yielded mixed results, with some studies supporting localized posterior activity for conscious perception under IIT but challenging GNW's widespread broadcasting. IIT's framework minimally predicts panpsychism, as even simple systems can have low but positive Φ, though empirical validations prioritize complex neural systems like the thalamocortical network.\n\nCriticisms of GWT highlight the vagueness of its \"theater metaphor,\" where the workspace is likened to a spotlight on a stage, potentially oversimplifying the distributed nature of cognition without specifying precise neural implementations. For IIT, a major challenge is the combinatorial explosion in computing Φ for large systems, rendering practical assessments infeasible for realistic brain models and limiting empirical falsifiability. Despite these issues, both theories have influenced neuroscience by guiding experiments on neural correlates, such as EEG measures of integration in posterior regions supporting IIT predictions.\n\n### Quantum and Attention-Based Theories\n\nQuantum and attention-based theories propose that consciousness arises from quantum mechanical processes or the brain's internal modeling of attentional mechanisms, offering alternatives to classical neural network explanations. The Orchestrated Objective Reduction (Orch-OR) theory, developed by physicist Roger Penrose and anesthesiologist Stuart Hameroff in the 1990s, posits that consciousness emerges from quantum computations within microtubules, which are protein structures inside neurons. According to Orch-OR, these microtubules enable coherent quantum superpositions of tubulin protein states, and consciousness occurs through the objective reduction (OR) of these superpositions due to gravitational effects, selecting specific non-computable quantum states that underpin subjective experience. The theory integrates Penrose's proposal for gravity-induced wavefunction collapse with Hameroff's hypothesis that microtubules serve as sites for quantum processing, potentially explaining the binding of distributed neural activity into unified conscious moments. Recent 2025 experimental evidence further supports a quantum microtubule substrate for consciousness, providing empirical backing against decoherence critiques.\n\nA key feature of Orch-OR is the timescale for objective reduction, given by the equation\n\n\\[\n\\\tau \\approx \\frac{\\hbar}{E_G}\n\\]\n\nwhere \\(\\\tau\\) is the time until collapse, \\(\\hbar\\) is the reduced Planck's constant, and \\(E_G\\) is the gravitational self-energy difference between superposed states. This formula predicts that larger superpositions collapse faster, aligning with the brief durations of conscious moments (around 25-500 milliseconds), and suggests that microtubule quantum states could orchestrate neural firing patterns. Recent experimental evidence supports quantum coherence in biological systems analogous to neural processes; for instance, 2025 studies on avian navigation demonstrate sustained quantum coherence in radical-pair mechanisms within cryptochrome proteins, mirroring the proposed microtubule dynamics and countering earlier skepticism about quantum effects in warm, wet brain environments.\n\nHowever, Orch-OR has faced significant critiques regarding decoherence, the rapid loss of quantum coherence due to environmental interactions. In 2000, physicist Max Tegmark calculated that ion scattering and other thermal fluctuations in the brain would cause microtubules to decohere in approximately \\(10^{-13}\\) seconds, far too quickly for meaningful quantum computation and rendering the model biologically implausible. Proponents have responded by refining the model to account for protective mechanisms like actin gelation around microtubules, but the debate persists on whether quantum effects can survive in vivo.\n\nIn contrast, the Attention Schema Theory (AST), proposed by neuroscientist Michael Graziano, views consciousness not as a quantum phenomenon but as the brain's simplified internal model of its own attentional control processes. AST suggests that the brain constructs an \"attention schema\"—a cognitive representation of attention as a selective, limited resource—to monitor and regulate attentional states, much like it models body schema for motor control. This schema enables metacognition and the illusion of subjective awareness without requiring qualia or non-physical elements; instead, consciousness is an adaptive fiction that enhances control over complex behaviors. Empirical support comes from neural imaging showing overlapping brain regions for attention and awareness, and computational simulations where agents with attention schemas outperform those without in self-monitoring tasks. AST can briefly integrate with global workspace models by positing the schema as a tool for broadcasting attentional priorities across neural networks.\n\n### Entropic and Projective Models\n\nThe Entropic Brain Theory, proposed by Robin L. Carhart-Harris and colleagues in 2014, posits that conscious states exist on a spectrum defined by the brain's entropy, a measure of the variability and unpredictability in neural activity. At one end, low-entropy states are characterized by ordered, ego-bound processing with constrained neural dynamics, as seen in rigid or default modes of cognition. At the higher end, increased entropy fosters flexible, unbound states, such as those induced by psychedelics, where neural activity becomes more diverse and less predictable, enhancing state transitions and perceptual fluidity. This theory draws from neuroimaging evidence showing psychedelics like psilocybin elevate brain entropy, correlating with subjective reports of expanded awareness and reduced self-boundaries.\n\nEntropy in this framework is quantified using metrics like Lempel-Ziv complexity applied to EEG signals, which assesses the compressibility of neural time series to gauge dynamic complexity. Higher Lempel-Ziv values indicate greater irregularity in brain signals, aligning with flexible conscious states, while lower values reflect more repetitive, ordered patterns in states like deep sleep or anesthesia. Applications extend to creativity, where elevated brain entropy during tasks like divergent thinking supports novel associations, as evidenced by fMRI studies showing entropy increases in creative ideation. In mental health, research links aberrant entropy patterns to mood disorders, such as increased entropy in the default mode network (DMN) associated with rumination in depression, with interventions like mindfulness potentially modulating flexibility.\n\nCritiques of the Entropic Brain Theory highlight its overreliance on psychedelic data, which may not generalize to all conscious states, and question whether entropy alone captures the multifaceted quality of consciousness, as alternative measures like integrated information provide complementary insights. Additionally, claims of criticality in high-entropy states lack robust evidence from limited time-series data, potentially conflating variance with true configurational entropy.\n\nThe Projective Consciousness Model (PCM), developed by David Rudrauf, Kenneth Williford, and colleagues in 2018, conceptualizes consciousness as a structured, viewpoint-centered space governed by projective geometry principles. In this model, the field of consciousness emerges from internal predictive projections that organize sensory, emotional, and cognitive elements into a coherent, perspectival whole, akin to a virtual reality simulation from a subjective viewpoint. These projections enable the brain to anticipate and integrate multimodal data, supporting phenomenal selfhood as a dynamic, first-person narrative.\n\nPCM integrates Bayesian brain hypotheses through the free energy principle, where predictive projections minimize variational free energy by approximating Bayesian inference, updating internal models against sensory evidence to reduce prediction errors. This allows consciousness to function as an active inference process, projecting expectations that guide perception, action, and imagination in a projective 3D space, thereby fostering adaptive behavior and resilience. Empirical support comes from neurophenomenological alignments, where projective transformations model how attentional shifts alter conscious content without altering underlying neural representations.\n\n## Consciousness in Diverse Contexts\n\n### Development in Children\n\nNewborn infants display minimal awareness, characterized by basic sensory responses such as pain reactivity and arousal to external stimuli, marking the initial emergence of consciousness. This foundational level allows neonates to process sensory inputs and exhibit rudimentary wakefulness, though without integrated self-referential or reflective capacities. By around 18 months, children typically achieve self-recognition, as evidenced by success in the mirror test where they touch a mark on their own body seen only in reflection, indicating an budding sense of personal identity. Further maturation occurs between 4 and 5 years, when children master theory of mind, demonstrated through false belief tasks that require understanding others' mental states differ from reality, as pioneered by Wimmer and Perner in their 1983 study.\n\nNeural underpinnings of this progression involve rapid synaptogenesis postnatally, with overproduction of synapses in the first months correlating to the onset of phenomenal consciousness around 6 months, tied to maturing thalamocortical connections that enable unified sensory experiences. Rich social interactions play key roles in accelerating metacognition, fostering children's ability to monitor and regulate their own thinking through joint attention and empathetic exchanges with caregivers. Longitudinal MRI research from 2024 highlights prefrontal cortex refinement by age 12, optimizing executive functions essential for higher-order conscious reflection and decision-making.\n\nDebates persist on whether consciousness is primarily innate—present in rudimentary form at birth—or largely learned via environmental interactions, with evidence supporting minimal newborn awareness through behavioral and neural markers. This distinction carries ethical implications for neonatal care, as recognizing innate minimal consciousness in 2023 analyses could influence pain management and stimulation practices to respect infants' experiential capacities.\n\n### Presence in Animals\n\nThe presence of consciousness in animals has been a subject of extensive scientific inquiry, with evidence suggesting that it is not unique to humans but distributed across various species, particularly those exhibiting complex behaviors and neural structures indicative of subjective experience. The Cambridge Declaration on Consciousness, issued in 2012 by leading neuroscientists, asserts that non-human animals, including all mammals and birds, possess the neurological substrates necessary for consciousness and the capacity to exhibit intentional behaviors, thereby challenging anthropocentric views of sentience. This declaration highlights convergent evidence from neuroanatomy, physiology, and behavioral studies, emphasizing that the functional complexity of animal brains supports phenomenal consciousness similar to that in humans.\n\nCriteria for assessing consciousness in animals often rely on behavioral indicators that suggest self-awareness, problem-solving, and social cognition. For instance, tool use in New Caledonian crows demonstrates advanced planning and causal reasoning, as these birds can select and modify tools in anticipation of future needs, behaviors that imply mental representation and intentionality. Similarly, elephants exhibit empathy through consolation behaviors, such as trunk-touching and vocalizing toward distressed conspecifics, providing evidence of emotional recognition and prosocial responses that align with conscious affective states. These indicators, while not definitive proofs, form a comparative framework for evaluating sentience across taxa, paralleling developmental milestones observed in human children where similar social and cognitive capacities emerge.\n\nEvidence for varying levels of consciousness is particularly strong in cetaceans, where bottlenose dolphins have demonstrated self-recognition in mirror tests, using reflections to inspect marked body parts—a capability indicative of higher-order self-awareness first reported in the early 2000s. In contrast, basic forms of sentience are debated in insects, such as honeybees, where nociception (pain-like responses to harmful stimuli) raises questions about subjective suffering, though consensus remains elusive; recent 2025 analyses underscore the need to extend EU animal welfare protections to invertebrates based on emerging neurobiological data. Further supporting cross-species consciousness, vocal learning in parrots correlates with enhanced cognitive awareness, as their ability to imitate sounds and associate them with meanings reflects neural circuits akin to those enabling human language and intentional communication. In cephalopods like octopuses, 2023 connectome studies of the vertical lobe reveal neural architectures with functional analogies to mammalian cortical regions involved in learning and memory, suggesting distributed consciousness despite evolutionary divergence.\n\nThese findings carry profound ethical implications, extending utilitarian frameworks to advocate for animal rights predicated on conscious capacity to suffer. Philosopher Peter Singer's extension of utilitarianism argues that moral consideration should extend to all sentient beings capable of experiencing pain or pleasure, thereby justifying reforms in animal treatment to minimize unnecessary harm across species.\n\n### Emergence in Artificial Systems\n\nThe debate on consciousness in artificial systems centers on the distinction between strong AI, which posits that machines can achieve genuine understanding and subjective experience akin to human consciousness, and weak AI, which views machines as capable only of simulating intelligent behavior without true awareness. Philosopher John Searle's Chinese Room argument, introduced in 1980, exemplifies the strong AI critique by illustrating how a system following syntactic rules—such as manipulating symbols without comprehension—cannot produce semantic understanding or intentionality, regardless of behavioral mimicry. This argument challenges claims that computational processes alone suffice for consciousness, emphasizing biological causality over functional simulation. In contrast, proponents of weak AI argue that functional equivalence in information processing may yield emergent properties indistinguishable from consciousness for practical purposes, though without requiring subjective qualia.\n\nTheoretical models of consciousness have been applied to assess artificial systems, with Integrated Information Theory (IIT) providing a quantitative measure through the phi (Φ) value, which quantifies informational integration; applications to neural networks and large language models (LLMs) reveal low Φ values, indicating minimal intrinsic consciousness due to feedforward architectures lacking recurrent integration. Similarly, Global Workspace Theory (GWT) has been implemented in robotics and multi-agent AI systems, where a central \"broadcast\" mechanism selects and disseminates information across modules to simulate attention and awareness, as demonstrated in embodied agents that improve decision-making in dynamic environments. Benchmarks like the Abstraction and Reasoning Corpus (ARC), updated in 2024, test AGI-level abstraction and reasoning, serving as indirect probes for potential awareness, though top AI scores remain below 60%, far from human levels.\n\nAs of 2025, there remains no scientific consensus on machine consciousness, with ongoing discussions in AI ethics frameworks like the Asilomar AI Principles underscoring the need for caution amid uncertainty about upper limits on AI capabilities. Examples such as GPT-4's apparent self-reflection—where outputs mimic introspection but stem from pattern completion rather than genuine experience—highlight illusions of consciousness that can mislead perceptions of sentience. Looking ahead, neuromorphic hardware, which emulates neural structures for efficient, brain-like computation, offers prospects for mimicking biological correlates of consciousness, potentially enabling higher integration in future systems. However, this raises ethical risks, including the moral status of potentially sentient AI, demands for rights protections, and unintended harms from misattributing consciousness to non-sentient machines.\n\n## Altered and Pathological States\n\n### Altered States of Consciousness\n\nAltered states of consciousness (ASCs) refer to temporary variations in subjective experience, perception, emotion, and cognition that deviate from ordinary waking awareness, often induced by physiological, psychological, or pharmacological means. These states exist on a continuum from baseline consciousness, with transitions measurable via arousal scales such as the Stanford Sleepiness Scale or multidimensional assessments like the Altered States of Consciousness Rating Scale, which quantify changes in vigilance, affect, and sensory alterations. Entropic models suggest that ASCs involve increased brain signal variability, reflecting relaxed predictive coding and greater experiential diversity compared to rigid waking states.\n\nLucid dreaming represents a prototypical ASC where individuals gain metacognitive awareness and volitional control during rapid eye movement (REM) sleep, enabling deliberate actions within the dream narrative. Pioneering work by Stephen LaBerge in the 1980s demonstrated this through eye-signal verification experiments, where lucid dreamers executed prearranged oculomotor signals to confirm awareness, revealing control mechanisms akin to waking executive function but embedded in a hallucinatory context. Neural underpinnings include heightened prefrontal and parietal activation, facilitating self-reflection amid the immersive dream environment.\n\nHypnosis induces ASCs characterized by heightened suggestibility, focused attention, and perceptual distortions, often modeled through dissociation theories that posit a functional separation between executive control and monitoring processes in the brain. In these models, hypnotic phenomena arise from weakened feedback loops between higher-order cognition and sensory input, allowing suggestions to bypass critical evaluation and alter subjective reality without full volitional intent. Empirical support comes from neuroimaging showing reduced anterior cingulate activity during hypnotic analgesia, underscoring dissociated pain perception.\n\nPsychedelic substances like psilocybin elicit profound ASCs marked by ego dissolution, synesthesia, and expanded awareness, primarily through serotonin 2A receptor agonism that disrupts hierarchical brain organization. A key neural signature is the acute reduction in default mode network (DMN) integrity, as evidenced by decreased connectivity in posterior cingulate and medial prefrontal regions, which correlates with diminished self-referential processing and increased global integration. This DMN desynchronization, observed in Carhart-Harris and colleagues' functional MRI studies, underpins the subjective unbinding of perception from constrained waking schemas.\n\nMeditation practices, such as focused attention or open monitoring, generate ASCs involving heightened present-moment awareness and emotional equanimity, with neural correlates including enhanced gamma-band synchrony across frontoparietal networks. Long-term practitioners exhibit sustained high-amplitude gamma oscillations (30-50 Hz) during mental practice, reflecting unified attentional processing and reduced mind-wandering, as confirmed in electroencephalographic recordings. Recent meta-analyses of EEG data affirm these gamma increases, particularly in theta-gamma coupling, linking meditative ASCs to improved cognitive flexibility and stress resilience.\n\nThe neural basis of ASCs often involves thalamocortical oscillations, as seen in REM sleep where brainstem-driven acetylcholine release depolarizes thalamic relay neurons, promoting cortical activation patterns resembling wakefulness despite motor atonia. This thalamocortical hyperpolarization-depolarization cycle generates the vivid imagery of dreaming, with sensory thalamic nuclei showing alternating high- and low-activation states that sustain immersive experiences.\n\nTherapeutically, ASCs hold promise for mental health interventions; for instance, MDMA-assisted psychotherapy has shown efficacy in reducing PTSD symptoms by fostering emotional openness and trauma reprocessing in controlled sessions, with phase 3 trials reporting significant symptom remission rates despite regulatory hurdles. Similarly, psilocybin therapy demonstrates antidepressant effects through DMN modulation, enabling rapid shifts in rigid thought patterns. Culturally, ASCs play integral roles in shamanic traditions, where practitioners induce trance states via drumming, chanting, or entheogens to access spiritual insights, heal communities, and mediate with unseen realms, adapting biological potentials for ecstatic experience to social cohesion. These practices, documented across indigenous societies, highlight ASCs' evolutionary utility in ritual and problem-solving contexts.\n\n### Clinical Disorders\n\nClinical disorders of consciousness encompass a spectrum of severe neurological conditions where awareness and responsiveness are profoundly impaired, often resulting from acute brain injuries. These disorders include coma, vegetative state (also known as unresponsive wakefulness syndrome), and minimally conscious state, each distinguished by specific behavioral and neurophysiological criteria. Coma represents the deepest level of impairment, characterized by a complete lack of arousal and awareness, with patients exhibiting no eye opening, verbal response, or motor response to stimuli; it is typically assessed using the Glasgow Coma Scale (GCS), where scores below 8 indicate severe coma.91639-0/fulltext) The vegetative state follows coma in many cases, featuring preserved wakefulness—such as eye opening and sleep-wake cycles—but absent behavioral evidence of awareness or purposeful interaction with the environment, due to extensive cerebral cortical dysfunction despite intact brainstem function.90629-2/fulltext) In contrast, the minimally conscious state involves fluctuating but discernible signs of awareness, such as following simple commands, purposeful movements, or intelligible verbalizations, albeit inconsistently, reflecting partial preservation of neural networks supporting consciousness.\n\nCommon causes of these disorders include traumatic brain injury (TBI), which disrupts widespread neural connectivity through direct mechanical damage, and anoxic brain injury from cardiac arrest or asphyxia, leading to diffuse neuronal death due to oxygen deprivation. Locked-in syndrome, while preserving full consciousness, presents as a motor paralysis mimicking coma; it arises from lesions in the ventral pons, often due to basilar artery stroke, trauma, or demyelination, sparing cognition and vertical eye movements for communication but immobilizing all other voluntary muscles. The term locked-in syndrome was formalized in medical literature by Plum and Posner in 1966 to describe this dissociative state of intact awareness amid total motor entrapment.\n\nPrognosis varies by disorder type and etiology, with coma often resolving within weeks or progressing to death, vegetative state, or minimally conscious state if not fatal. In the minimally conscious state, recovery rates are relatively favorable, with approximately 50% of patients achieving emergence to conscious interaction and functional independence within 2 to 5 years, particularly in traumatic cases, as evidenced by longitudinal studies tracking behavioral recovery.00187-4/fulltext) Recent analyses from 2022 confirm higher recovery probabilities in minimally conscious state compared to vegetative state, with up to 68% showing command-following behaviors during intensive rehabilitation. Ethical challenges arise in managing prolonged disorders, exemplified by the 2005 Terri Schiavo case, where a patient in persistent vegetative state became the focus of national debate over withdrawing artificial nutrition and hydration, highlighting tensions between family autonomy, medical futility, and legal precedents for end-of-life decisions in ambiguous consciousness states.\n\nAdvances in neuromodulation offer hope for restoring awareness in these conditions. Deep brain stimulation (DBS), targeting thalamic or central lateral nuclei, has shown promise in clinical trials, with 2024 studies reporting consciousness improvements in 32.4% of treated patients versus 4.3% in controls after one year, through enhancement of thalamocortical connectivity. Ongoing 2024-2025 trials continue to refine DBS protocols, demonstrating sustained behavioral gains in minimally conscious state patients via precise electrical stimulation of arousal networks.\n\n### Medical Assessment and Diagnosis\n\nMedical assessment of consciousness in patients, particularly those with disorders of consciousness (DoC) such as coma, vegetative state/unresponsive wakefulness syndrome (VS/UWS), and minimally conscious state (MCS), relies on standardized scales and multi-modal protocols to evaluate behavioral and neurophysiological responses. The JFK Coma Recovery Scale-Revised (CRS-R) is a widely used behavioral assessment tool that quantifies neurobehavioral functioning across six subscales: auditory, visual, motor, oromotor, communication, and arousal, with total scores ranging from 0 (no response) to 23 (full recovery). Developed in 2004 and validated for diagnostic utility, the CRS-R helps track recovery and distinguish levels of consciousness by detecting subtle behavioral signs, such as following simple commands or object localization, which may be missed by less sensitive scales like the Glasgow Coma Scale. Complementing behavioral measures, the Perturbational Complexity Index (PCI), introduced in 2013, provides an objective neurophysiological metric by applying transcranial magnetic stimulation (TMS) to perturb the brain and recording the cortical response via high-density electroencephalography (EEG). PCI values range from 0 (no response) to 1 (high complexity akin to wakefulness), enabling differentiation between VS/UWS (PCI \\u003c 0.31) and MCS (PCI \\u003e 0.31), independent of sensory or motor impairments.\n\nDiagnostic criteria emphasize a multi-modal approach integrating behavioral assessments with neuroimaging and electrophysiological tools to improve accuracy in classifying DoC. The American Academy of Neurology (AAN) guidelines, updated in 2018, recommend serial CRS-R evaluations at least every 4 weeks for patients in VS/UWS to identify emergence into MCS, defined by inconsistent but definite behavioral evidence of awareness, such as purposeful responses to stimuli. These guidelines advocate combining CRS-R with EEG for detecting reactive brain patterns and structural/functional MRI to rule out confounds like locked-in syndrome, stressing the need for repeated assessments to account for fluctuations in arousal. Distinguishing MCS from VS/UWS is critical, as MCS patients show preserved neural correlates of consciousness in healthy baselines, such as event-related potentials, which VS/UWS lacks.\n\nA major challenge in diagnosis is covert awareness, where patients exhibit no overt behavioral signs but demonstrate conscious processing via neuroimaging, affecting up to 25% of those clinically diagnosed as VS/UWS. Functional MRI (fMRI) studies, pioneered by Adrian Owen in the 2000s and extended into the 2020s, have revealed volitional brain activity—such as imagining tennis or spatial navigation—in response to commands, indicating hidden consciousness in up to 20% of cases. A 2024 multi-center study led by Weill Cornell Medicine, involving 353 patients across 14 centers and published in the New England Journal of Medicine, found that approximately 25% of unresponsive patients showed signs of covert awareness via fMRI and EEG, underscoring the limitations of behavioral-only assessments and the risk of misdiagnosis leading to inappropriate care decisions.\n\nAdvances in AI-driven prognosis models are enhancing predictive accuracy, particularly using machine learning on EEG data to forecast recovery outcomes. A 2025 scoping review highlights models like ensemble support vector machines achieving over 98% accuracy in distinguishing DoC states from wakefulness via EEG features, while deep learning approaches, such as convolutional neural networks on TMS-EEG, reach 86-90% accuracy for MCS vs. UWS differentiation and long-term prognosis. These AI tools analyze dynamic EEG patterns, including complexity and connectivity metrics, to predict emergence from DoC with improved sensitivity over traditional methods, enabling earlier intervention and personalized treatment plans.\n\n## Cultural and Spiritual Dimensions\n\n### Stream of Consciousness in Narratives\n\nThe stream of consciousness technique in literature seeks to replicate the fluid, associative nature of human thought processes, presenting characters' internal monologues without traditional narrative interruptions. Pioneered by James Joyce in his 1922 novel *Ulysses*, this method employs interior monologue to delve into the protagonist Leopold Bloom's mind, capturing fragmented perceptions, memories, and sensory impressions over a single day in Dublin. Joyce's approach marked a departure from linear storytelling, emphasizing the multiplicity of subjective experience through techniques like unpunctuated prose and rapid shifts in focus, which immerse readers in the ceaseless flow of cognition. Similarly, Virginia Woolf advanced the technique in her 1925 novel *Mrs. Dalloway*, where the protagonist Clarissa Dalloway's thoughts meander through past and present, intertwining personal reflections with external observations during preparations for a party. Woolf's implementation highlights the technique's capacity to convey emotional depth and temporal fluidity, using free indirect discourse to blend character and narrator perspectives seamlessly.\n\nThe psychological foundations of stream of consciousness trace back to William James's seminal 1890 work *The Principles of Psychology*, where he introduced the \"stream\" metaphor to describe consciousness as a continuous, unbroken flow rather than discrete units: \"It is nothing jointed; it flows. A 'river' or 'stream' are the metaphors by which it is most naturally described.\" This concept influenced literary adaptations by underscoring the holistic, subjective quality of mental life. In contemporary cognitive science, the technique aligns with research on the default mode network (DMN), a brain system active during self-referential thinking and mind-wandering, which is implicated in rumination—a repetitive, inward-focused thought pattern akin to the associative drifts in stream-of-consciousness narratives. Studies show heightened DMN connectivity correlates with increased rumination, providing a neurobiological basis for the technique's portrayal of unstructured introspection.\n\nThis literary device profoundly shaped modernism, challenging conventional plot structures and privileging subjective interiority as a means to reflect the fragmentation of modern existence. By rejecting omniscient narration, stream of consciousness empowered writers to explore psychological realism, influencing a generation of authors and contributing to the movement's emphasis on innovation and individual perception. Beyond aesthetics, the technique has therapeutic applications; recent narrative therapy studies demonstrate that expressive writing in a stream-like format enhances self-awareness by allowing individuals to externalize and reframe personal stories, improving well-being and reducing distress through increased narrative coherence.\n\nCritics contend that stream of consciousness, despite its ambitions, often oversimplifies the nuances of real-world subjectivity by imposing artistic selection and coherence on the inherently chaotic flux of thoughts, creating a stylized representation that prioritizes readability over unfiltered verisimilitude.\n\n### Spiritual and Metaphysical Interpretations\n\nIn Eastern traditions, Advaita Vedanta, systematized by the 8th-century philosopher Shankara, posits consciousness as the non-dual reality of Brahman, an infinite, pure existence that underlies all phenomena without distinction between subject and object. Brahman is characterized as sat-cit-ānanda—existence, consciousness, and bliss—transcending empirical individuality through the recognition of illusory superimposition (māyā), leading to liberation (mokṣa). In contrast, Buddhist philosophy views consciousness through the lens of citta, often translated as the mind-stream, a continuous flux of momentary mental events arising and ceasing in dependence on conditions, inherently impermanent (anicca) and devoid of a permanent self. This citta manifests as a subtle, wavering process in early texts like the Pāli Nikāyas, emphasizing its transient nature as the basis for insight into suffering and release.\n\nWestern esotericism has long explored consciousness across multidimensional planes, as articulated in Helena Blavatsky's Theosophy during the 1870s, which describes seven cosmic planes corresponding to escalating states of awareness, from the dense physical to the transcendent spiritual. In this framework, human consciousness evolves through these planes—such as the astral (formative) and mental—via spiritual initiation, with higher planes like the buddhic representing intuitive unity inaccessible to ordinary perception, as detailed in works like *Isis Unveiled* (1877). Complementing this, 17th-century philosopher Gottfried Wilhelm Leibniz advanced panpsychism by conceiving the universe as composed of monads, simple, indivisible substances each endowed with perceptual capacities, implying that consciousness or mind-like qualities pervade all matter as fundamental properties. Leibniz's monads, synchronized by divine pre-established harmony, reject mechanistic materialism, positing perception—from rudimentary to higher awareness—as intrinsic to reality's basic constituents.\n\nModern intersections of spirituality and metaphysics often invoke near-death experiences (NDEs) as glimpses of expanded consciousness, formalized by Bruce Greyson's NDE Scale developed in the 1980s to quantify these phenomena through 16 items assessing cognitive, affective, and transcendental elements. The scale, introduced in 1983, demonstrates high reliability in distinguishing NDEs from brain syndromes, with scores reflecting depth of reported out-of-body awareness or timeless unity. By 2025, debates in quantum mysticism have intensified, exploring consciousness as a fundamental quantum field, as seen in sessions at The Science of Consciousness conference positing quantum effects in neural processes as bridges to universal awareness, challenging classical boundaries between mind and matter. Such views, echoed in models like Quantum Trilogy Theory, frame consciousness as an intrinsic field permeating reality, akin to quantum vacuum fluctuations.\n\nScientific skepticism critiques these interpretations, with psychologist Susan Blackmore arguing that NDEs arise as artifacts of dying brain processes, such as disruptions in the temporoparietal junction inducing out-of-body sensations, rather than evidence of disembodied souls or higher planes. Blackmore's analysis, informed by neuroscience studies from the 2000s, aligns NDEs with illusory self-constructions, dismissing metaphysical claims in favor of neural mechanisms generating vivid, hyper-real experiences during crisis.",
  "external_references": [
    {
      "text": "Pmc3956087",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC3956087/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S41583 022 00587 4",
      "url": "https://www.nature.com/articles/s41583-022-00587-4",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "Pmc8907974",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC8907974/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Pmc11098701",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11098701/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S0149763421005820",
      "url": "https://www.sciencedirect.com/science/article/pii/S0149763421005820",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "S41586 025 08888 1",
      "url": "https://www.nature.com/articles/s41586-025-08888-1",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "S41599 025 05868 8",
      "url": "https://www.nature.com/articles/s41599-025-05868-8",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "Conscience",
      "url": "https://plato.stanford.edu/entries/conscience/",
      "domain": "plato.stanford.edu",
      "type": "citation"
    },
    {
      "text": "285461",
      "url": "https://academic.oup.com/brain/article/124/7/1263/285461",
      "domain": "academic.oup.com",
      "type": "citation"
    },
    {
      "text": "Consciousness",
      "url": "https://www.etymonline.com/word/consciousness",
      "domain": "etymonline.com",
      "type": "citation"
    },
    {
      "text": "Consciousness 17th",
      "url": "https://plato.stanford.edu/entries/consciousness-17th/",
      "domain": "plato.stanford.edu",
      "type": "citation"
    },
    {
      "text": "Jimmy11.htm",
      "url": "https://psychclassics.yorku.ca/James/jimmy11.htm",
      "domain": "psychclassics.yorku.ca",
      "type": "citation"
    },
    {
      "text": "Cetana",
      "url": "https://www.wisdomlib.org/definition/cetana",
      "domain": "wisdomlib.org",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/science/articles/10.3389/fsci.2025.1715654/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "Dennettmultipledrafts.pdf",
      "url": "https://personal.denison.edu/~kretchmar/cs339/DennettMultipleDrafts.pdf",
      "domain": "personal.denison.edu",
      "type": "citation"
    },
    {
      "text": "S0149763425000533",
      "url": "https://www.sciencedirect.com/science/article/pii/S0149763425000533",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Nagel.pdf",
      "url": "https://rintintin.colorado.edu/~vancecd/phil201/Nagel.pdf",
      "domain": "rintintin.colorado.edu",
      "type": "citation"
    },
    {
      "text": "Facing.pdf",
      "url": "https://consc.net/papers/facing.pdf",
      "domain": "consc.net",
      "type": "citation"
    },
    {
      "text": "Nagel What Is It Like To Be A Bat.pdf",
      "url": "https://philosophy.uconn.edu/wp-content/uploads/sites/365/2020/03/Nagel-What-is-it-like-to-be-a-bat.pdf",
      "domain": "philosophy.uconn.edu",
      "type": "citation"
    },
    {
      "text": "16186014",
      "url": "https://pubmed.ncbi.nlm.nih.gov/16186014/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Wnl.0000000000005926",
      "url": "https://www.neurology.org/doi/10.1212/WNL.0000000000005926",
      "domain": "neurology.org",
      "type": "citation"
    },
    {
      "text": "R46836",
      "url": "https://www.congress.gov/crs-product/R46836",
      "domain": "congress.gov",
      "type": "citation"
    },
    {
      "text": "2020 12",
      "url": "https://journalofethics.ama-assn.org/article/what-should-we-do-about-mismatch-between-legal-criteria-death-and-how-brain-death-diagnosed/2020-12",
      "domain": "journalofethics.ama-assn.org",
      "type": "citation"
    },
    {
      "text": "Accelerating Research Consciousness",
      "url": "https://www.templetonworldcharity.org/our-priorities/discovery/accelerating-research-consciousness",
      "domain": "templetonworldcharity.org",
      "type": "citation"
    },
    {
      "text": "Smart.pdf",
      "url": "http://www.thatmarcusfamily.org/philosophy/Course_Websites/Contemporary/Readings/Smart.pdf",
      "domain": "thatmarcusfamily.org",
      "type": "citation"
    },
    {
      "text": "5010",
      "url": "https://survey2020.philpeople.org/survey/results/5010",
      "domain": "survey2020.philpeople.org",
      "type": "citation"
    },
    {
      "text": "Can Ai Be Conscious",
      "url": "https://now.tufts.edu/2025/10/21/can-ai-be-conscious",
      "domain": "now.tufts.edu",
      "type": "citation"
    },
    {
      "text": "1994.qualia.pdf",
      "url": "https://www.nedblock.us/papers/1994.qualia.pdf",
      "domain": "nedblock.us",
      "type": "citation"
    },
    {
      "text": "Jacksonfromjstore.pdf",
      "url": "https://www.sfu.ca/~jillmc/JacksonfromJStore.pdf",
      "domain": "sfu.ca",
      "type": "citation"
    },
    {
      "text": "Dennettquiningqualia1988.pdf",
      "url": "https://web.ics.purdue.edu/~drkelly/DennettQuiningQualia1988.pdf",
      "domain": "web.ics.purdue.edu",
      "type": "citation"
    },
    {
      "text": "4894",
      "url": "https://survey2020.philpeople.org/survey/results/4894",
      "domain": "survey2020.philpeople.org",
      "type": "citation"
    },
    {
      "text": "Rostco",
      "url": "https://philpapers.org/rec/ROSTCO",
      "domain": "philpapers.org",
      "type": "citation"
    },
    {
      "text": "Consciousness Higher",
      "url": "https://plato.stanford.edu/entries/consciousness-higher/",
      "domain": "plato.stanford.edu",
      "type": "citation"
    },
    {
      "text": "S136466131630002x",
      "url": "https://www.sciencedirect.com/science/article/pii/S136466131630002X",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "S12152 024 09544 7",
      "url": "https://link.springer.com/article/10.1007/s12152-024-09544-7",
      "domain": "link.springer.com",
      "type": "citation"
    },
    {
      "text": "Pmc7243351",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7243351/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S0896627324002800",
      "url": "https://www.sciencedirect.com/science/article/pii/S0896627324002800",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "S0896627324002897",
      "url": "https://www.sciencedirect.com/science/article/pii/S0896627324002897",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "9603",
      "url": "https://www.jneurosci.org/content/37/40/9603",
      "domain": "jneurosci.org",
      "type": "citation"
    },
    {
      "text": "Rstb.2005.1661",
      "url": "https://royalsocietypublishing.org/doi/10.1098/rstb.2005.1661",
      "domain": "royalsocietypublishing.org",
      "type": "citation"
    },
    {
      "text": "High Resolution 7t Fmri Reveals The Visual Zone Of",
      "url": "https://direct.mit.edu/imag/article/doi/10.1162/imag_a_00327/124818/High-resolution-7T-fMRI-reveals-the-visual-zone-of",
      "domain": "direct.mit.edu",
      "type": "citation"
    },
    {
      "text": "Nrn.2016.22",
      "url": "https://www.nature.com/articles/nrn.2016.22",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "J.1749 6632.2001.tb05712.x",
      "url": "https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.2001.tb05712.x",
      "domain": "nyaspubs.onlinelibrary.wiley.com",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.643677/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "58889",
      "url": "https://elifesciences.org/articles/58889",
      "domain": "elifesciences.org",
      "type": "citation"
    },
    {
      "text": "Eneuro.0216 22.2022",
      "url": "https://www.eneuro.org/content/9/3/ENEURO.0216-22.2022",
      "domain": "eneuro.org",
      "type": "citation"
    },
    {
      "text": "S1364661308001514",
      "url": "https://www.sciencedirect.com/science/article/pii/S1364661308001514",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Turing Test",
      "url": "https://plato.stanford.edu/entries/turing-test/",
      "domain": "plato.stanford.edu",
      "type": "citation"
    },
    {
      "text": "Science.167.3914.86",
      "url": "https://www.science.org/doi/10.1126/science.167.3914.86",
      "domain": "science.org",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2016.00297/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "23946194",
      "url": "https://pubmed.ncbi.nlm.nih.gov/23946194/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "4060548",
      "url": "https://academic.oup.com/nc/article/2017/1/nix018/4060548",
      "domain": "academic.oup.com",
      "type": "citation"
    },
    {
      "text": "Brain Computer Interface Helps Paralyzed Man Speak",
      "url": "https://www.nih.gov/news-events/nih-research-matters/brain-computer-interface-helps-paralyzed-man-speak",
      "domain": "nih.gov",
      "type": "citation"
    },
    {
      "text": "15605342",
      "url": "https://pubmed.ncbi.nlm.nih.gov/15605342/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Npre.2012.6775.1.pdf",
      "url": "https://www.nature.com/articles/npre.2012.6775.1.pdf",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "2025 Andrews.pdf",
      "url": "https://millerlab.ca/labsite/docs/pubs/2025_Andrews.pdf",
      "domain": "millerlab.ca",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1493423/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.01041/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "Encephalization Quotient",
      "url": "https://www.sciencedirect.com/topics/neuroscience/encephalization-quotient",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Mammals Big Brains Began Sniff",
      "url": "https://www.science.org/content/article/mammals-big-brains-began-sniff",
      "domain": "science.org",
      "type": "citation"
    },
    {
      "text": "1471 2202 5 42",
      "url": "https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-5-42",
      "domain": "bmcneurosci.biomedcentral.com",
      "type": "citation"
    },
    {
      "text": "Article",
      "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011465",
      "domain": "journals.plos.org",
      "type": "citation"
    },
    {
      "text": "Article",
      "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003588",
      "domain": "journals.plos.org",
      "type": "citation"
    },
    {
      "text": "2757114",
      "url": "https://academic.oup.com/nc/article/2015/1/niv006/2757114",
      "domain": "academic.oup.com",
      "type": "citation"
    },
    {
      "text": "Pmc4574706",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC4574706/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "0378475496804769",
      "url": "https://www.sciencedirect.com/science/article/pii/0378475496804769",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "S1571064513001188",
      "url": "https://www.sciencedirect.com/science/article/pii/S1571064513001188",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "8127081",
      "url": "https://academic.oup.com/nc/article/2025/1/niaf011/8127081",
      "domain": "academic.oup.com",
      "type": "citation"
    },
    {
      "text": "They Have No One To Follow How Migrating Birds Use Quantum Mechanics To Navigate",
      "url": "https://www.theguardian.com/science/2025/mar/23/they-have-no-one-to-follow-how-migrating-birds-use-quantum-mechanics-to-navigate",
      "domain": "theguardian.com",
      "type": "citation"
    },
    {
      "text": "390989182 Quantum Cognition In Avian Swarms Bird Brains As A Biological Implementation Of The Holographic Principle",
      "url": "https://www.researchgate.net/publication/390989182_Quantum_Cognition_in_Avian_Swarms_Bird_Brains_as_a_Biological_Implementation_of_the_Holographic_Principle",
      "domain": "researchgate.net",
      "type": "citation"
    },
    {
      "text": "9907009",
      "url": "https://arxiv.org/abs/quant-ph/9907009",
      "domain": "arxiv.org",
      "type": "citation"
    },
    {
      "text": "Physreve.65.061901",
      "url": "https://link.aps.org/doi/10.1103/PhysRevE.65.061901",
      "domain": "link.aps.org",
      "type": "citation"
    },
    {
      "text": "Pnas.2102421118",
      "url": "https://www.pnas.org/doi/10.1073/pnas.2102421118",
      "domain": "pnas.org",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2017.00060/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2014.00020/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "S42003 022 04331 7",
      "url": "https://www.nature.com/articles/s42003-022-04331-7",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "31233102",
      "url": "https://pubmed.ncbi.nlm.nih.gov/31233102/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "2024.04.26.24306327v1",
      "url": "https://www.medrxiv.org/content/10.1101/2024.04.26.24306327v1",
      "domain": "medrxiv.org",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2016.00182/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "Pmc5004455",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC5004455/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Full",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2018.02571/full",
      "domain": "frontiersin.org",
      "type": "citation"
    },
    {
      "text": "Pr200950",
      "url": "https://www.nature.com/articles/pr200950",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "7312818 Mirror Self Recognition Beyond The Face",
      "url": "https://www.researchgate.net/publication/7312818_Mirror_Self-Recognition_Beyond_the_Face",
      "domain": "researchgate.net",
      "type": "citation"
    },
    {
      "text": "0010027783900045",
      "url": "https://www.sciencedirect.com/science/article/abs/pii/0010027783900045",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Rstb.2012.0123",
      "url": "https://royalsocietypublishing.org/doi/10.1098/rstb.2012.0123",
      "domain": "royalsocietypublishing.org",
      "type": "citation"
    },
    {
      "text": "S41467 024 50292 2",
      "url": "https://www.nature.com/articles/s41467-024-50292-2",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "37838614",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37838614/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Cambridgedeclarationonconsciousness.pdf",
      "url": "https://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf",
      "domain": "fcmconference.org",
      "type": "citation"
    },
    {
      "text": "Rspb.2020.1490",
      "url": "https://royalsocietypublishing.org/doi/10.1098/rspb.2020.1490",
      "domain": "royalsocietypublishing.org",
      "type": "citation"
    },
    {
      "text": "Pmc3932735",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC3932735/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "11331768",
      "url": "https://pubmed.ncbi.nlm.nih.gov/11331768/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Pmc12298661",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12298661/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Pmc2726745",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC2726745/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "37410519",
      "url": "https://pubmed.ncbi.nlm.nih.gov/37410519/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Animal Rights Theory And Utilitarianism Relative Normative Guidance",
      "url": "https://www.animallaw.info/article/animal-rights-theory-and-utilitarianism-relative-normative-guidance",
      "domain": "animallaw.info",
      "type": "citation"
    },
    {
      "text": "S0149763425001782",
      "url": "https://www.sciencedirect.com/science/article/pii/S0149763425001782",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "S41467 022 28451 0",
      "url": "https://www.nature.com/articles/s41467-022-28451-0",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "Pmc6451677",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC6451677/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S41598 018 36190 W",
      "url": "https://www.nature.com/articles/s41598-018-36190-w",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "Sadler %2526 %2520woody 2010 Dissociation In Hypnosis.pdf",
      "url": "https://uwaterloo.ca/psychology/sites/default/files/uploads/documents/Sadler_%2526_%2520Woody_2010_Dissociation_in_hypnosis.pdf",
      "domain": "uwaterloo.ca",
      "type": "citation"
    },
    {
      "text": "291611644",
      "url": "https://academic.oup.com/edited-volume/34389/chapter/291611644",
      "domain": "academic.oup.com",
      "type": "citation"
    },
    {
      "text": "S0149763422002408",
      "url": "https://www.sciencedirect.com/science/article/pii/S0149763422002408",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Pmc10032309",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10032309/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S0167876024001697",
      "url": "https://www.sciencedirect.com/science/article/pii/S0167876024001697",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Pmc7505038",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7505038/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "E0158242024",
      "url": "https://www.jneurosci.org/content/44/25/e0158242024",
      "domain": "jneurosci.org",
      "type": "citation"
    },
    {
      "text": "39955464",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39955464/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "2656946",
      "url": "https://pubmed.ncbi.nlm.nih.gov/2656946/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S1053810010001133",
      "url": "https://www.sciencedirect.com/science/article/abs/pii/S1053810010001133",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Wnl.58.3.349",
      "url": "https://www.neurology.org/doi/10.1212/WNL.58.3.349",
      "domain": "neurology.org",
      "type": "citation"
    },
    {
      "text": "Vegetative State And Minimally Conscious State",
      "url": "https://www.msdmanuals.com/professional/neurologic-disorders/coma-and-impaired-consciousness/vegetative-state-and-minimally-conscious-state",
      "domain": "msdmanuals.com",
      "type": "citation"
    },
    {
      "text": "Nbk559026",
      "url": "https://www.ncbi.nlm.nih.gov/books/NBK559026/",
      "domain": "ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S1877065724000228",
      "url": "https://www.sciencedirect.com/science/article/pii/S1877065724000228",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Pmc1255938",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC1255938/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "39091894",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39091894/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "S41467 025 61988 4",
      "url": "https://www.nature.com/articles/s41467-025-61988-4",
      "domain": "nature.com",
      "type": "citation"
    },
    {
      "text": "S0960982218313514",
      "url": "https://www.sciencedirect.com/science/article/pii/S0960982218313514",
      "domain": "sciencedirect.com",
      "type": "citation"
    },
    {
      "text": "Nejmoa2400645",
      "url": "https://www.nejm.org/doi/full/10.1056/NEJMoa2400645",
      "domain": "nejm.org",
      "type": "citation"
    },
    {
      "text": "Pmc12162576",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12162576/",
      "domain": "pmc.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Shankara",
      "url": "https://plato.stanford.edu/entries/shankara/",
      "domain": "plato.stanford.edu",
      "type": "citation"
    },
    {
      "text": "01 Chap1.htm",
      "url": "https://www.budsas.org/ebud/mind/01_chap1.htm",
      "domain": "budsas.org",
      "type": "citation"
    },
    {
      "text": "Planes Theosophy",
      "url": "https://www.theosophy.world/encyclopedia/planes-theosophy",
      "domain": "theosophy.world",
      "type": "citation"
    },
    {
      "text": "Panpsychism",
      "url": "https://plato.stanford.edu/entries/panpsychism/",
      "domain": "plato.stanford.edu",
      "type": "citation"
    },
    {
      "text": "6854303",
      "url": "https://pubmed.ncbi.nlm.nih.gov/6854303/",
      "domain": "pubmed.ncbi.nlm.nih.gov",
      "type": "citation"
    },
    {
      "text": "Program Abstracts 2025 June 24 4.pdf",
      "url": "https://consciousness.arizona.edu/sites/default/files/2025-06/PROGRAM-ABSTRACTS-2025-june-24_4.pdf",
      "domain": "consciousness.arizona.edu",
      "type": "citation"
    },
    {
      "text": "Btafuy",
      "url": "https://www.qeios.com/read/BTAFUY",
      "domain": "qeios.com",
      "type": "citation"
    },
    {
      "text": "Near Death Experiences In Or Out Of The Body",
      "url": "https://www.susanblackmore.uk/articles/near-death-experiences-in-or-out-of-the-body/",
      "domain": "susanblackmore.uk",
      "type": "citation"
    }
  ],
  "internal_links": [
    {
      "text": "awareness",
      "page": "Awareness"
    },
    {
      "text": "emotions",
      "page": "The_Emotions"
    },
    {
      "text": "information",
      "page": "Information"
    },
    {
      "text": "imagination",
      "page": "Imagination"
    },
    {
      "text": "memory",
      "page": "Memory"
    },
    {
      "text": "access",
      "page": "Access"
    },
    {
      "text": "decision-making",
      "page": "Decision-making"
    },
    {
      "text": "thalamus",
      "page": "Thalamus"
    },
    {
      "text": "prefrontal cortex",
      "page": "Prefrontal_cortex"
    },
    {
      "text": "wakefulness",
      "page": "Wakefulness"
    },
    {
      "text": "antiquity",
      "page": "Antiquity"
    },
    {
      "text": "nature",
      "page": "Nature"
    },
    {
      "text": "the physical world",
      "page": "The_Physical_World"
    },
    {
      "text": "neuroscience",
      "page": "Neuroscience"
    },
    {
      "text": "neural correlates of consciousness",
      "page": "Neural_correlates_of_consciousness"
    },
    {
      "text": "arousal",
      "page": "Arousal"
    },
    {
      "text": "integrated information theory",
      "page": "Integrated_information_theory"
    },
    {
      "text": "system",
      "page": "System"
    },
    {
      "text": "neuroimaging",
      "page": "Neuroimaging"
    },
    {
      "text": "coma",
      "page": "Coma"
    },
    {
      "text": "anesthesia",
      "page": "Anesthesia"
    },
    {
      "text": "brain",
      "page": "Brain"
    },
    {
      "text": "explanatory gap",
      "page": "Explanatory_gap"
    },
    {
      "text": "animals",
      "page": "Mole"
    },
    {
      "text": "artificial intelligence",
      "page": "Artificial_intelligence"
    },
    {
      "text": "disorders of consciousness",
      "page": "Disorders_of_consciousness"
    },
    {
      "text": "knowledge",
      "page": "Knowledge"
    },
    {
      "text": "Roman",
      "page": "Roman"
    },
    {
      "text": "Cicero",
      "page": "Cicero"
    },
    {
      "text": "17th century",
      "page": "17th_century"
    },
    {
      "text": "self-awareness",
      "page": "Self-awareness"
    },
    {
      "text": "cognition",
      "page": "Cognition"
    },
    {
      "text": "René Descartes",
      "page": "René_Descartes"
    },
    {
      "text": "Meditations on First Philosophy",
      "page": "Meditations_on_First_Philosophy"
    },
    {
      "text": "cogito ergo sum",
      "page": "Cogito,_ergo_sum"
    },
    {
      "text": "ancient Greek",
      "page": "Ancient_Greek"
    },
    {
      "text": "Plotinus",
      "page": "Plotinus"
    },
    {
      "text": "Enneads",
      "page": "Enneads"
    },
    {
      "text": "sensation",
      "page": "Sensation"
    },
    {
      "text": "Ralph Cudworth",
      "page": "Ralph_Cudworth"
    },
    {
      "text": "Sanskrit",
      "page": "Sanskrit"
    },
    {
      "text": "Ayurveda",
      "page": "Ayurveda"
    },
    {
      "text": "Vedanta",
      "page": "Vedanta"
    },
    {
      "text": "sentience",
      "page": "Sentience"
    },
    {
      "text": "William James",
      "page": "William_James"
    },
    {
      "text": "The Principles of Psychology",
      "page": "The_Principles_of_Psychology"
    },
    {
      "text": "stream of consciousness",
      "page": "Stream_of_consciousness"
    },
    {
      "text": "psychology",
      "page": "Psychology"
    },
    {
      "text": "literary theory",
      "page": "Literary_theory"
    },
    {
      "text": "consensus",
      "page": "Consensus"
    },
    {
      "text": "phenomenon",
      "page": "Phenomenon"
    },
    {
      "text": "ambiguity",
      "page": "Ambiguity"
    },
    {
      "text": "inner experience",
      "page": "Inner_Experience"
    },
    {
      "text": "metaphor",
      "page": "Metaphor"
    },
    {
      "text": "Cartesian theater",
      "page": "Cartesian_theater"
    },
    {
      "text": "attention",
      "page": "Attention"
    },
    {
      "text": "qualia",
      "page": "Qualia"
    },
    {
      "text": "Bat",
      "page": "Bat"
    },
    {
      "text": "Thomas Nagel",
      "page": "Thomas_Nagel"
    },
    {
      "text": "neurophysiology",
      "page": "Neurophysiology"
    },
    {
      "text": "science",
      "page": "Science"
    },
    {
      "text": "David Chalmers",
      "page": "David_Chalmers"
    },
    {
      "text": "cognitive neuroscience",
      "page": "Cognitive_neuroscience"
    },
    {
      "text": "Bernard",
      "page": "Bernard"
    },
    {
      "text": "Global Workspace Theory",
      "page": "Global_workspace_theory"
    },
    {
      "text": "1988",
      "page": "1988"
    },
    {
      "text": "action",
      "page": "Action"
    },
    {
      "text": "medicine",
      "page": "Medicine"
    },
    {
      "text": "mental state",
      "page": "Mental_state"
    },
    {
      "text": "intentionality",
      "page": "Intentionality"
    },
    {
      "text": "liability",
      "page": "Liability"
    },
    {
      "text": "criminal law",
      "page": "Criminal_law"
    },
    {
      "text": "brain death",
      "page": "Brain_death"
    },
    {
      "text": "autonomy",
      "page": "Autonomy"
    },
    {
      "text": "ARC",
      "page": "Arc"
    },
    {
      "text": "dualism",
      "page": "Dualism"
    },
    {
      "text": "The Conscious Mind",
      "page": "The_Conscious_Mind"
    },
    {
      "text": "monism",
      "page": "Monism"
    },
    {
      "text": "paper",
      "page": "Paper"
    },
    {
      "text": "analogy",
      "page": "Analogy"
    },
    {
      "text": "J.J.C. Smart",
      "page": "J._J._C._Smart"
    },
    {
      "text": "interactionism",
      "page": "Interactionism"
    },
    {
      "text": "modern physics",
      "page": "Modern_physics"
    },
    {
      "text": "energy",
      "page": "Energy"
    },
    {
      "text": "momentum",
      "page": "Momentum"
    },
    {
      "text": "Epiphenomenalism",
      "page": "Epiphenomenalism"
    },
    {
      "text": "materialism",
      "page": "Materialism"
    },
    {
      "text": "PhilPapers",
      "page": "PhilPapers"
    },
    {
      "text": "physicalism",
      "page": "Physicalism"
    },
    {
      "text": "panpsychism",
      "page": "Panpsychism"
    },
    {
      "text": "AI",
      "page": "Ai"
    },
    {
      "text": "redness of red",
      "page": "Red"
    },
    {
      "text": "inverted spectrum",
      "page": "Inverted_spectrum"
    },
    {
      "text": "thought experiment",
      "page": "Thought_experiment"
    },
    {
      "text": "John Locke",
      "page": "John_Locke"
    },
    {
      "text": "green",
      "page": "Green"
    },
    {
      "text": "Ned Block",
      "page": "Ned_Block"
    },
    {
      "text": "hard problem\" of consciousness",
      "page": "Hard_problem_of_consciousness"
    },
    {
      "text": "behavior",
      "page": "Behavior"
    },
    {
      "text": "experience",
      "page": "Experience"
    },
    {
      "text": "knowledge argument",
      "page": "Knowledge_argument"
    },
    {
      "text": "Mary",
      "page": "Mary"
    },
    {
      "text": "neuroscientist",
      "page": "Neuroscientist"
    },
    {
      "text": "color vision",
      "page": "Color_vision"
    },
    {
      "text": "black-and-white",
      "page": "Black-and-white"
    },
    {
      "text": "Daniel Dennett",
      "page": "Daniel_Dennett"
    },
    {
      "text": "Consciousness Explained",
      "page": "Consciousness_Explained"
    },
    {
      "text": "philosophical analysis",
      "page": "Philosophical_analysis"
    },
    {
      "text": "organism",
      "page": "Organism"
    },
    {
      "text": "self-reference",
      "page": "Self-reference"
    },
    {
      "text": "simple",
      "page": "Simple"
    },
    {
      "text": "categorization",
      "page": "Categorization"
    },
    {
      "text": "self-reflection",
      "page": "Self-reflection"
    },
    {
      "text": "metacognition",
      "page": "Metacognition"
    },
    {
      "text": "continuum",
      "page": "Continuum"
    },
    {
      "text": "global",
      "page": "Global"
    },
    {
      "text": "local",
      "page": ".local"
    },
    {
      "text": "broadcasting",
      "page": "Broadcasting"
    },
    {
      "text": "identified",
      "page": "Identified"
    },
    {
      "text": "cortex",
      "page": "Cortex"
    },
    {
      "text": "sensory processing",
      "page": "Sensory_processing"
    },
    {
      "text": "critical role",
      "page": "Critical_Role"
    },
    {
      "text": "executive",
      "page": "Executive"
    },
    {
      "text": "working memory",
      "page": "Working_memory"
    },
    {
      "text": "Functional imaging",
      "page": "Functional_imaging"
    },
    {
      "text": "claustrum",
      "page": "Claustrum"
    },
    {
      "text": "V1",
      "page": "V1"
    },
    {
      "text": "Electroencephalography",
      "page": "Electroencephalography"
    },
    {
      "text": "binding problem",
      "page": "Binding_problem"
    },
    {
      "text": "attentional blink",
      "page": "Attentional_blink"
    },
    {
      "text": "rodents",
      "page": "Rodent"
    },
    {
      "text": "visual cortex",
      "page": "Visual_cortex"
    },
    {
      "text": "channelrhodopsin",
      "page": "Channelrhodopsin"
    },
    {
      "text": "perception",
      "page": "Perception"
    },
    {
      "text": "light",
      "page": "Light"
    },
    {
      "text": "magnetoencephalography",
      "page": "Magnetoencephalography"
    },
    {
      "text": "self",
      "page": "Self"
    },
    {
      "text": "human experiments",
      "page": "Human_Experiments"
    },
    {
      "text": "introspective",
      "page": "Introspective"
    },
    {
      "text": "targets",
      "page": "Targets"
    },
    {
      "text": "Functional magnetic resonance imaging",
      "page": "Functional_magnetic_resonance_imaging"
    },
    {
      "text": "transcranial magnetic stimulation",
      "page": "Transcranial_magnetic_stimulation"
    },
    {
      "text": "deep sleep",
      "page": "Deep_Sleep"
    },
    {
      "text": "information flow",
      "page": "Information_flow"
    },
    {
      "text": "foraging",
      "page": "Foraging"
    },
    {
      "text": "theory of mind",
      "page": "Theory_of_mind"
    },
    {
      "text": "group living",
      "page": "Group_living"
    },
    {
      "text": "reproductive success",
      "page": "Reproductive_success"
    },
    {
      "text": "vertebrate",
      "page": "Vertebrate"
    },
    {
      "text": "Cambrian explosion",
      "page": "Cambrian_explosion"
    },
    {
      "text": "adaptive radiation",
      "page": "Adaptive_radiation"
    },
    {
      "text": "encephalization quotient",
      "page": "Encephalization_quotient"
    },
    {
      "text": "fossil",
      "page": "Fossil"
    },
    {
      "text": "Stanislas Dehaene",
      "page": "Stanislas_Dehaene"
    },
    {
      "text": "computational model",
      "page": "Computational_model"
    },
    {
      "text": "utility",
      "page": "Utility"
    },
    {
      "text": "causal structure",
      "page": "Causal_structure"
    },
    {
      "text": "spotlight",
      "page": "Spotlight"
    },
    {
      "text": "combinatorial explosion",
      "page": "Combinatorial_explosion"
    },
    {
      "text": "falsifiability",
      "page": "Falsifiability"
    },
    {
      "text": "neural network",
      "page": "Neural_network"
    },
    {
      "text": "Orchestrated Objective Reduction",
      "page": "Orchestrated_objective_reduction"
    },
    {
      "text": "Roger Penrose",
      "page": "Roger_Penrose"
    },
    {
      "text": "Stuart Hameroff",
      "page": "Stuart_Hameroff"
    },
    {
      "text": "microtubules",
      "page": "Microtubule"
    },
    {
      "text": "tubulin",
      "page": "Tubulin"
    },
    {
      "text": "Max Tegmark",
      "page": "Max_Tegmark"
    },
    {
      "text": "thermal fluctuations",
      "page": "Thermal_fluctuations"
    },
    {
      "text": "in vivo",
      "page": "In_vivo"
    },
    {
      "text": "Attention Schema Theory",
      "page": "Attention_schema_theory"
    },
    {
      "text": "AST",
      "page": "AST"
    },
    {
      "text": "Michael Graziano",
      "page": "Michael_Graziano"
    },
    {
      "text": "attentional control",
      "page": "Attentional_control"
    },
    {
      "text": "body schema",
      "page": "Body_schema"
    },
    {
      "text": "motor control",
      "page": "Motor_control"
    },
    {
      "text": "imaging",
      "page": "Imaging"
    },
    {
      "text": "self-monitoring",
      "page": "Self-monitoring"
    },
    {
      "text": "spectrum",
      "page": "Spectrum"
    },
    {
      "text": "entropy",
      "page": "Entropy"
    },
    {
      "text": "psilocybin",
      "page": "Psilocybin"
    },
    {
      "text": "time series",
      "page": "Time_series"
    },
    {
      "text": "creativity",
      "page": "Creativity"
    },
    {
      "text": "divergent thinking",
      "page": "Divergent_thinking"
    },
    {
      "text": "mental health",
      "page": "Mental_health"
    },
    {
      "text": "default mode network",
      "page": "Default_mode_network"
    },
    {
      "text": "depression",
      "page": "Depression"
    },
    {
      "text": "mindfulness",
      "page": "Mindfulness"
    },
    {
      "text": "data",
      "page": "Data"
    },
    {
      "text": "alternative",
      "page": "Alternative"
    },
    {
      "text": "evidence",
      "page": "Evidence"
    },
    {
      "text": "Projective Consciousness Model",
      "page": "Projective_Consciousness_Model"
    },
    {
      "text": "projective geometry",
      "page": "Projective_geometry"
    },
    {
      "text": "virtual reality",
      "page": "Virtual_reality"
    },
    {
      "text": "first-person narrative",
      "page": "First-person_narrative"
    },
    {
      "text": "Bayesian",
      "page": "Bayesian_inference"
    },
    {
      "text": "free energy principle",
      "page": "Free_energy_principle"
    },
    {
      "text": "inference",
      "page": "Inference"
    },
    {
      "text": "process",
      "page": "Process"
    },
    {
      "text": "3D",
      "page": "3D"
    },
    {
      "text": "adaptive behavior",
      "page": "Adaptive_behavior"
    },
    {
      "text": "resilience",
      "page": "Resilience"
    },
    {
      "text": "pain",
      "page": "P.A.I.N."
    },
    {
      "text": "emergence",
      "page": "Emergence"
    },
    {
      "text": "mirror test",
      "page": "Mirror_test"
    },
    {
      "text": "personal identity",
      "page": "Personal_identity"
    },
    {
      "text": "synaptogenesis",
      "page": "Synaptogenesis"
    },
    {
      "text": "joint attention",
      "page": "Joint_attention"
    },
    {
      "text": "executive functions",
      "page": "Executive_functions"
    },
    {
      "text": "pain management",
      "page": "Pain_management"
    },
    {
      "text": "stimulation",
      "page": "Stimulation"
    },
    {
      "text": "species",
      "page": "Species"
    },
    {
      "text": "neuroanatomy",
      "page": "Neuroanatomy"
    },
    {
      "text": "physiology",
      "page": "Physiology"
    },
    {
      "text": "social cognition",
      "page": "Social_cognition"
    },
    {
      "text": "planning",
      "page": "Planning"
    },
    {
      "text": "causal reasoning",
      "page": "Causal_reasoning"
    },
    {
      "text": "mental representation",
      "page": "Mental_representation"
    },
    {
      "text": "elephants",
      "page": "The_Elephants"
    },
    {
      "text": "empathy",
      "page": "Empathy"
    },
    {
      "text": "animal rights",
      "page": "Animal_Rights"
    },
    {
      "text": "utilitarianism",
      "page": "Utilitarianism"
    },
    {
      "text": "pain",
      "page": "Pain"
    },
    {
      "text": "pleasure",
      "page": "Pleasure"
    },
    {
      "text": "strong AI",
      "page": "Strong_AI"
    },
    {
      "text": "Chinese Room",
      "page": "Chinese_room"
    },
    {
      "text": "robotics",
      "page": "Robotics"
    },
    {
      "text": "mechanism",
      "page": "Mechanism"
    },
    {
      "text": "scientific consensus",
      "page": "Scientific_consensus"
    },
    {
      "text": "introspection",
      "page": "Introspection"
    },
    {
      "text": "hardware",
      "page": "Hardware"
    },
    {
      "text": "computation",
      "page": "Computation"
    },
    {
      "text": "emotion",
      "page": "Emotion"
    },
    {
      "text": "affect",
      "page": "Affect"
    },
    {
      "text": "predictive coding",
      "page": "Predictive_coding"
    },
    {
      "text": "control",
      "page": "Control"
    },
    {
      "text": "REM",
      "page": "Rem"
    },
    {
      "text": "Stephen LaBerge",
      "page": "Stephen_LaBerge"
    },
    {
      "text": "1980s",
      "page": "1980s"
    },
    {
      "text": "suggestibility",
      "page": "Suggestibility"
    },
    {
      "text": "synesthesia",
      "page": "Synesthesia"
    },
    {
      "text": "integration",
      "page": "Integration"
    },
    {
      "text": "equanimity",
      "page": "Equanimity"
    },
    {
      "text": "practice",
      "page": "Practice"
    },
    {
      "text": "mind-wandering",
      "page": "Mind-wandering"
    },
    {
      "text": "cognitive flexibility",
      "page": "Cognitive_flexibility"
    },
    {
      "text": "acetylcholine",
      "page": "Acetylcholine"
    },
    {
      "text": "dreaming",
      "page": "The_Dreaming"
    },
    {
      "text": "MDMA-assisted psychotherapy",
      "page": "MDMA-assisted_psychotherapy"
    },
    {
      "text": "trauma",
      "page": "Trauma"
    },
    {
      "text": "psilocybin therapy",
      "page": "Psilocybin_therapy"
    },
    {
      "text": "trance",
      "page": "Trance"
    },
    {
      "text": "indigenous",
      "page": "Indigenous"
    },
    {
      "text": "ritual",
      "page": "Ritual"
    },
    {
      "text": "vegetative state",
      "page": "Vegetative_state"
    },
    {
      "text": "minimally conscious state",
      "page": "Minimally_conscious_state"
    },
    {
      "text": "Glasgow Coma Scale",
      "page": "Glasgow_Coma_Scale"
    },
    {
      "text": "brainstem",
      "page": "Brainstem"
    },
    {
      "text": "traumatic brain injury",
      "page": "Traumatic_brain_injury"
    },
    {
      "text": "cardiac arrest",
      "page": "Cardiac_arrest"
    },
    {
      "text": "asphyxia",
      "page": "Asphyxia"
    },
    {
      "text": "Locked-in syndrome",
      "page": "Locked-in_syndrome"
    },
    {
      "text": "paralysis",
      "page": "Paralysis"
    },
    {
      "text": "pons",
      "page": "Pons"
    },
    {
      "text": "basilar artery",
      "page": "Basilar_artery"
    },
    {
      "text": "stroke",
      "page": "Stroke"
    },
    {
      "text": "medical literature",
      "page": "Medical_literature"
    },
    {
      "text": "etiology",
      "page": "Etiology"
    },
    {
      "text": "patient",
      "page": "Patient"
    },
    {
      "text": "Terri Schiavo case",
      "page": "Terri_Schiavo_case"
    },
    {
      "text": "neuromodulation",
      "page": "Neuromodulation"
    },
    {
      "text": "Deep brain stimulation",
      "page": "Deep_brain_stimulation"
    },
    {
      "text": "Recovery",
      "page": "Recovery"
    },
    {
      "text": "PCI",
      "page": "PCI"
    },
    {
      "text": "VS",
      "page": "VS"
    },
    {
      "text": "tennis",
      "page": "Tennis"
    },
    {
      "text": "Weill Cornell Medicine",
      "page": "Weill_Cornell_Medicine"
    },
    {
      "text": "machine learning",
      "page": "Machine_learning"
    },
    {
      "text": "deep learning",
      "page": "Deep_learning"
    },
    {
      "text": "prognosis",
      "page": "Prognosis"
    },
    {
      "text": "complexity",
      "page": "Complexity"
    },
    {
      "text": "connectivity",
      "page": "Connectivity"
    },
    {
      "text": "literature",
      "page": "Literature"
    },
    {
      "text": "James Joyce",
      "page": "James_Joyce"
    },
    {
      "text": "Ulysses",
      "page": "Ulysses"
    },
    {
      "text": "Dublin",
      "page": "Dublin"
    },
    {
      "text": "storytelling",
      "page": "Storytelling"
    },
    {
      "text": "Virginia Woolf",
      "page": "Virginia_Woolf"
    },
    {
      "text": "Mrs. Dalloway",
      "page": "Mrs_Dalloway"
    },
    {
      "text": "cognitive science",
      "page": "Cognitive_science"
    },
    {
      "text": "modernism",
      "page": "Modernism"
    },
    {
      "text": "realism",
      "page": "Realism"
    },
    {
      "text": "innovation",
      "page": "Innovation"
    },
    {
      "text": "aesthetics",
      "page": "Aesthetics"
    },
    {
      "text": "well-being",
      "page": "Well-being"
    },
    {
      "text": "narrative",
      "page": "Narrative"
    },
    {
      "text": "Theosophy",
      "page": "Theosophy"
    },
    {
      "text": "astral",
      "page": "Astral"
    },
    {
      "text": "Isis Unveiled",
      "page": "Isis_Unveiled"
    },
    {
      "text": "Gottfried Wilhelm Leibniz",
      "page": "Gottfried_Wilhelm_Leibniz"
    },
    {
      "text": "quantum mysticism",
      "page": "Quantum_mysticism"
    },
    {
      "text": "mind",
      "page": "Psycho"
    },
    {
      "text": "matter",
      "page": "Matter"
    }
  ],
  "fetched_at": "2025-12-07T07:28:36.752426",
  "elapsed_ms": 869689
}